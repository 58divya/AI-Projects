{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab8309bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image \n",
    "from PIL import ImageEnhance\n",
    "from skimage.io import imread\n",
    "import os, random, pathlib, warnings, itertools, math\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import gc\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing import image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94aaa094",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='./Vegetable Images/train'\n",
    "valid_dir ='./Vegetable Images/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b6473c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('predict.h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "185efab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "category={\n",
    "    0: 'Bean', 1: 'Bitter_Gourd', 2: 'Bottle_Gourd', 3 : 'Brinjal', 4: \"Broccoli\", 5: 'Cabbage', 6: 'Capsicum', 7: 'Carrot', 8: 'Cauliflower',\n",
    "    9: 'Cucumber', 10: 'Papaya', 11: 'Potato', 12: 'Pumpkin', 13 : \"Radish\", 14: \"Tomato\"\n",
    "}\n",
    "\n",
    "def predict_image(filename, model):\n",
    "    img_ = image.load_img(filename, target_size=(150, 150))\n",
    "    img_array = image.img_to_array(img_)\n",
    "    img_processed = np.expand_dims(img_array, axis=0) \n",
    "    img_processed /= 255.   \n",
    "    \n",
    "    prediction = model.predict(img_processed)\n",
    "    index = np.argmax(prediction)\n",
    "    \n",
    "    plt.title(\"Prediction - {}\".format(category[index]))\n",
    "    plt.imshow(img_array)\n",
    "    \n",
    "def predict_dir(filedir,model):\n",
    "    cols=3\n",
    "    pos=0\n",
    "    images=[]\n",
    "    total_images=len(os.listdir(filedir))\n",
    "    rows=total_images//cols + 1\n",
    "    \n",
    "    true=filedir.split('/')[-1]\n",
    "    \n",
    "    for i in sorted(os.listdir(filedir)):\n",
    "        images.append(os.path.join(filedir,i))\n",
    "        \n",
    "    for subplot, imggg in enumerate(images):\n",
    "        img_ = image.load_img(imggg, target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img_)\n",
    "        img_processed = np.expand_dims(img_array, axis=0) \n",
    "        img_processed /= 255.\n",
    "        prediction = model.predict(img_processed)\n",
    "        index = np.argmax(prediction)\n",
    "        \n",
    "        pred=category.get(index)\n",
    "        if pred==true:\n",
    "            pos+=1\n",
    "\n",
    "    acc=pos/total_images\n",
    "    print(\"Accuracy for {orignal}: {:.2f} ({pos}/{total})\".format(acc,pos=pos,total=total_images,orignal=true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c94042",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [150, 150]\n",
    "\n",
    "inception = InceptionV3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "for layer in inception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = inception.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(128,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "prediction = Dense(15, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=inception.input, outputs=prediction)\n",
    "\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0a0b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rescale = 1./255,\n",
    "                                         shear_range = 0.2,\n",
    "                                         zoom_range = 0.2,\n",
    "                                         horizontal_flip = True)\n",
    "\n",
    "valid_datagen = image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 26,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size = (224, 224),\n",
    "    batch_size = 26, \n",
    "    class_mode = 'categorical')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
